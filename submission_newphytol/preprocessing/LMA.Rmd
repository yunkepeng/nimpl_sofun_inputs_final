---
output:
  html_document: default
  pdf_document: default
  word_document: default
---

---
title: "Prediction field of LMA"
author: "Yunke Peng"
date: "Nov 11 2020"
output: html_document
---

## Introduction about Global nc files

Here LMA was done separately, because (1) pre-processing of TRY maps takes a long time, whcih requires the step to resample data from TRY map to 0.5 grids, (2) knn method also takes a long time, and it necessarily needs global predictors from PPFD, Tg and alpha, therefore this file is better to be done separately.

A brief information about LMA, and three main predictors that will be used in knn.
 * alpha (SPLASH: asssited by David Sandoval)
 * PPFD (umol/m2/s) (WFDEI: http://www.eu-watch.org/gfx_content/documents/README-WFDEI%20(v2016).pdf)
 * Tg (degree celcius) (CRU ts 4.01: https://crudata.uea.ac.uk/cru/data/hrg/cru_ts_4.01/)
 * LMA (g/m2) (TRY Global traits map 3km: https://isp.uv.es/code/try.html)

alpha, PPFD, Tg will directly use 0.5 * 0.5 grids data from final_ncfile/

## First time LMA output
```{r}
library(raster)
library(ncdf4)
library(dplyr)
library(maps)
library(rgdal)
devtools::load_all("/Users/yunpeng/yunkepeng/latest_packages/rbeni/") 
#1. Input 0.5 resolution df, and convert to raster before resampling (e.g. elevation.nc)
elev_nc <- read_nc_onefile("~/data/watch_wfdei/WFDEI-elevation.nc")
elev <- as.data.frame(nc_to_df(elev_nc, varnam = "elevation"))
summary(elev)
names(elev) <- c("lon","lat","z")
coordinates(elev) <- ~lon+lat 
gridded(elev) <- TRUE
raster_z <- raster(elev, "z") 

bounding_box <- extent(-180, 180, -90, 90)
raster_z_crop <- crop(raster_z, bounding_box)
raster_z_crop

#2. Input 3km LMA raster that needs resampled
#Original data source: https://isp.uv.es/code/try.html
raster_SLA <- raster("~/data/TRY_maps/data_orig/SLA_3km_v1.tif")
raster_SLA_crop <- crop(raster_SLA, bounding_box)
raster_SLA_crop

#raster of SLA (0.02694946* 0.02694946) will be resampled to 0.5*0.5 resolution, based on provided elevation raster 
res(raster_z_crop)
res(raster_SLA_crop)

resampled_SLA <- raster::resample(raster_SLA_crop, raster_z_crop, method="ngb")
df_SLA <- stack(resampled_SLA)
df_SLA <- as.data.frame(df_SLA,xy = TRUE)
names(df_SLA) <- c("lon","lat","SLA")
summary(df_SLA)

df_SLA2 <- subset(df_SLA,(SLA > 0)) # remove some amazingly wrong number (negative!)
df_SLA2$LMA <- 1000/df_SLA2$SLA #mm2/mg -> g/m2
LMA_df <- df_SLA2[,c("lon","lat","LMA")]  


library(raster)
library(ncdf4)
library(dplyr)      # for data wrangling
library(ggplot2)    # for awesome graphics
library(rsample)    # for creating validation splits
library(recipes)    # for feature engineering
# Modeling packages
library(caret)       # for fitting KNN models
library(h2o)       # for resampling and model training
library(AmesHousing)
library(modeldata)
library(rsample)
library(dslabs)
library(purrr)
library(randomForest)

# recap
summary(LMA_df)
dim(LMA_df)

#Map after resamping
plot_map3(LMA_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#We start our work from here - using knn method to fill our grids

#(1) first, input Tg, PPFD, alpha directly from final_nc/ (the data directly used in nimpl simulation)
# NA value was converted to 9999 in previous step (to prevent FPE in nimpl), therefore, converting it back
Tg_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/Tg.nc"), varnam = "Tg")
#Tg_df$myvar[Tg_df$myvar == 9999] <- NA
names(Tg_df) <- c("lon","lat","Tg")

PPFD_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/PPFD.nc"), varnam = "PPFD")
#PPFD_df$myvar[PPFD_df$myvar == 9999] <- NA
names(PPFD_df) <- c("lon","lat","PPFD")

alpha_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/alpha.nc"), varnam = "alpha")
#alpha_df$myvar[alpha_df$myvar == 9999] <- NA
names(alpha_df) <- c("lon","lat","alpha")

merge1 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                list(Tg_df,PPFD_df,alpha_df,LMA_df))
summary(merge1) # we will start knn from here, it is clear that LMA has less data, and this is what we aim to interpolate based on knn

merge2 <- subset(merge1,PPFD>0) # only select available grids (in land). This will be furtherly used to determine training and testing (predicted) data.
dim(merge2)

#(2) start knn

all_data <- merge2[,c("LMA","lat","Tg","alpha","PPFD")] # this is final input will be used in knn, which removed lon here.

training_data <- subset(all_data,LMA>0) #only select available LMA data as training data

testing_data <- subset(all_data,is.na(LMA)==TRUE)  #only select NA-LMA data as testing data, which will be used in knn at the end.

dim(training_data)
dim(testing_data)

# we will use those 19020 grids to predict those 44816 grids
# 3. knn training
cv <- trainControl(
  method = "cv", 
  number = 10
)

# Create a hyperparameter grid search
hyper_grid <- expand.grid(
  k = floor(seq(1, 15, length.out = 16))
)
library(keras)
set.seed(2)
knn_fit <- train(LMA ~., data = training_data,
                 method = "knn",
                 trControl=cv,
                 preProcess = c("center", "scale"),
                 tuneGrid = hyper_grid)

knn_fit # it indicated k =9 as the best design, with R2=0.61, RMSE = 10.58

# output prediction data and add it in testing_data
set.seed(2)
test_pred <- predict(knn_fit,newdata=testing_data)
testing_data$LMA <- test_pred

#rbind, and merge back with lon.
final <- rbind(training_data,testing_data)

lon_data <- merge2[,c("lon","lat","Tg","alpha","PPFD")]

final2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lat","Tg","alpha","PPFD"),all.x=TRUE), 
                list(final,lon_data))

#form final3 dataframe as final output, and plot
LMA_knn_df <- final2[,c("lon","lat","LMA")]

#This map is LMA after knn method
plot_map3(LMA_knn_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#Finally, ready to be outputted! It merges from 63836 grids to 259200 cells, which makes it as a perfect standard for nimpl input
LMA_knn_df2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                     list(merge1[,c("lon","lat")],LMA_knn_df))

df_LMA <- LMA_knn_df2[order(LMA_knn_df2[,2],LMA_knn_df2[,1]),]

#prepare lon and lat
ncin <- nc_open("~/data/watch_wfdei/WFDEI-elevation.nc")
lon <- ncvar_get(ncin,"lon")
lat<-ncvar_get(ncin,"lat")

#output nc file - In Euler its path is same: "~/data/nimpl_sofun_inputs/map/Final_ncfile"
LMA_nc <- list(df_to_grid(df_LMA,varnam = "LMA", lonnam = "lon", latnam = "lat"))
names(LMA_nc) <- "LMA"
varams = "LMA"
test <- list(lon,lat,LMA_nc,varams)
names(test) <- c("lon","lat","vars","varams")
write_nc2(test,varnams = "LMA",long_name = "Leaf mass per area",units = "g m-2",
          path = "~/data/nimpl_sofun_inputs/map/Final_ncfile/LMA.nc")

knn_fit
summary(df_LMA)
df_LMA1 <- df_LMA
``` 


## Second time LMA output
```{r}
library(raster)
library(ncdf4)
library(dplyr)
library(maps)
library(rgdal)
#1. Input 0.5 resolution df, and convert to raster before resampling (e.g. elevation.nc)
elev_nc <- read_nc_onefile("~/data/watch_wfdei/WFDEI-elevation.nc")
elev <- as.data.frame(nc_to_df(elev_nc, varnam = "elevation"))
summary(elev)
names(elev) <- c("lon","lat","z")
coordinates(elev) <- ~lon+lat 
gridded(elev) <- TRUE
raster_z <- raster(elev, "z") 

bounding_box <- extent(-180, 180, -90, 90)
raster_z_crop <- crop(raster_z, bounding_box)
raster_z_crop

#2. Input 3km LMA raster that needs resampled
#Original data source: https://isp.uv.es/code/try.html
raster_SLA <- raster("~/data/TRY_maps/data_orig/SLA_3km_v1.tif")
raster_SLA_crop <- crop(raster_SLA, bounding_box)
raster_SLA_crop

#raster of SLA (0.02694946* 0.02694946) will be resampled to 0.5*0.5 resolution, based on provided elevation raster 
res(raster_z_crop)
res(raster_SLA_crop)

resampled_SLA <- raster::resample(raster_SLA_crop, raster_z_crop, method="ngb")
df_SLA <- stack(resampled_SLA)
df_SLA <- as.data.frame(df_SLA,xy = TRUE)
names(df_SLA) <- c("lon","lat","SLA")
summary(df_SLA)

df_SLA2 <- subset(df_SLA,(SLA > 0)) # remove some amazingly wrong number (negative!)
df_SLA2$LMA <- 1000/df_SLA2$SLA #mm2/mg -> g/m2
LMA_df <- df_SLA2[,c("lon","lat","LMA")]  


library(raster)
library(ncdf4)
library(dplyr)      # for data wrangling
library(ggplot2)    # for awesome graphics
library(rsample)    # for creating validation splits
library(recipes)    # for feature engineering
# Modeling packages
library(caret)       # for fitting KNN models
library(h2o)       # for resampling and model training
library(AmesHousing)
library(modeldata)
library(rsample)
library(dslabs)
library(purrr)
library(randomForest)

# recap
summary(LMA_df)
dim(LMA_df)

#Map after resamping
plot_map3(LMA_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#We start our work from here - using knn method to fill our grids

#(1) first, input Tg, PPFD, alpha directly from final_nc/ (the data directly used in nimpl simulation)
# NA value was converted to 9999 in previous step (to prevent FPE in nimpl), therefore, converting it back
Tg_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/Tg.nc"), varnam = "Tg")
#Tg_df$myvar[Tg_df$myvar == 9999] <- NA
names(Tg_df) <- c("lon","lat","Tg")

PPFD_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/PPFD.nc"), varnam = "PPFD")
#PPFD_df$myvar[PPFD_df$myvar == 9999] <- NA
names(PPFD_df) <- c("lon","lat","PPFD")

alpha_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/alpha.nc"), varnam = "alpha")
#alpha_df$myvar[alpha_df$myvar == 9999] <- NA
names(alpha_df) <- c("lon","lat","alpha")

merge1 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                list(Tg_df,PPFD_df,alpha_df,LMA_df))
summary(merge1) # we will start knn from here, it is clear that LMA has less data, and this is what we aim to interpolate based on knn

merge2 <- subset(merge1,PPFD>0) # only select available grids (in land). This will be furtherly used to determine training and testing (predicted) data.
dim(merge2)

#(2) start knn

all_data <- merge2[,c("LMA","lat","Tg","alpha","PPFD")] # this is final input will be used in knn, which removed lon here.

training_data <- subset(all_data,LMA>0) #only select available LMA data as training data

testing_data <- subset(all_data,is.na(LMA)==TRUE)  #only select NA-LMA data as testing data, which will be used in knn at the end.

dim(training_data)
dim(testing_data)

# we will use those 19020 grids to predict those 44816 grids
# 3. knn training
cv <- trainControl(
  method = "cv", 
  number = 10
)

# Create a hyperparameter grid search
hyper_grid <- expand.grid(
  k = floor(seq(1, 15, length.out = 16))
)
library(keras)
set.seed(2)
knn_fit <- train(LMA ~., data = training_data,
                 method = "knn",
                 trControl=cv,
                 preProcess = c("center", "scale"),
                 tuneGrid = hyper_grid)

knn_fit # it indicated k =9 as the best design, with R2=0.61, RMSE = 10.58

# output prediction data and add it in testing_data
set.seed(2)
test_pred <- predict(knn_fit,newdata=testing_data)
testing_data$LMA <- test_pred

#rbind, and merge back with lon.
final <- rbind(training_data,testing_data)

lon_data <- merge2[,c("lon","lat","Tg","alpha","PPFD")]

final2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lat","Tg","alpha","PPFD"),all.x=TRUE), 
                list(final,lon_data))

#form final3 dataframe as final output, and plot
LMA_knn_df <- final2[,c("lon","lat","LMA")]

#This map is LMA after knn method
plot_map3(LMA_knn_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#Finally, ready to be outputted! It merges from 63836 grids to 259200 cells, which makes it as a perfect standard for nimpl input
LMA_knn_df2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                     list(merge1[,c("lon","lat")],LMA_knn_df))

df_LMA <- LMA_knn_df2[order(LMA_knn_df2[,2],LMA_knn_df2[,1]),]

#prepare lon and lat
ncin <- nc_open("~/data/watch_wfdei/WFDEI-elevation.nc")
lon <- ncvar_get(ncin,"lon")
lat<-ncvar_get(ncin,"lat")

#output nc file - In Euler its path is same: "~/data/nimpl_sofun_inputs/map/Final_ncfile"
LMA_nc <- list(df_to_grid(df_LMA,varnam = "LMA", lonnam = "lon", latnam = "lat"))
names(LMA_nc) <- "LMA"
varams = "LMA"
test <- list(lon,lat,LMA_nc,varams)
names(test) <- c("lon","lat","vars","varams")
write_nc2(test,varnams = "LMA",long_name = "Leaf mass per area",units = "g m-2",
          path = "~/data/nimpl_sofun_inputs/map/Final_ncfile/LMA.nc")

knn_fit
summary(df_LMA)
df_LMA2 <- df_LMA
```  

## Third time LMA output
```{r}
library(raster)
library(ncdf4)
library(dplyr)
library(maps)
library(rgdal)
#1. Input 0.5 resolution df, and convert to raster before resampling (e.g. elevation.nc)
elev_nc <- read_nc_onefile("~/data/watch_wfdei/WFDEI-elevation.nc")
elev <- as.data.frame(nc_to_df(elev_nc, varnam = "elevation"))
summary(elev)
names(elev) <- c("lon","lat","z")
coordinates(elev) <- ~lon+lat 
gridded(elev) <- TRUE
raster_z <- raster(elev, "z") 

bounding_box <- extent(-180, 180, -90, 90)
raster_z_crop <- crop(raster_z, bounding_box)
raster_z_crop

#2. Input 3km LMA raster that needs resampled
#Original data source: https://isp.uv.es/code/try.html
raster_SLA <- raster("~/data/TRY_maps/data_orig/SLA_3km_v1.tif")
raster_SLA_crop <- crop(raster_SLA, bounding_box)
raster_SLA_crop

#raster of SLA (0.02694946* 0.02694946) will be resampled to 0.5*0.5 resolution, based on provided elevation raster 
res(raster_z_crop)
res(raster_SLA_crop)

resampled_SLA <- raster::resample(raster_SLA_crop, raster_z_crop, method="ngb")
df_SLA <- stack(resampled_SLA)
df_SLA <- as.data.frame(df_SLA,xy = TRUE)
names(df_SLA) <- c("lon","lat","SLA")
summary(df_SLA)

df_SLA2 <- subset(df_SLA,(SLA > 0)) # remove some amazingly wrong number (negative!)
df_SLA2$LMA <- 1000/df_SLA2$SLA #mm2/mg -> g/m2
LMA_df <- df_SLA2[,c("lon","lat","LMA")]  


library(raster)
library(ncdf4)
library(dplyr)      # for data wrangling
library(ggplot2)    # for awesome graphics
library(rsample)    # for creating validation splits
library(recipes)    # for feature engineering
# Modeling packages
library(caret)       # for fitting KNN models
library(h2o)       # for resampling and model training
library(AmesHousing)
library(modeldata)
library(rsample)
library(dslabs)
library(purrr)
library(randomForest)

# recap
summary(LMA_df)
dim(LMA_df)

#Map after resamping
plot_map3(LMA_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#We start our work from here - using knn method to fill our grids

#(1) first, input Tg, PPFD, alpha directly from final_nc/ (the data directly used in nimpl simulation)
# NA value was converted to 9999 in previous step (to prevent FPE in nimpl), therefore, converting it back
Tg_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/Tg.nc"), varnam = "Tg")
#Tg_df$myvar[Tg_df$myvar == 9999] <- NA
names(Tg_df) <- c("lon","lat","Tg")

PPFD_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/PPFD.nc"), varnam = "PPFD")
#PPFD_df$myvar[PPFD_df$myvar == 9999] <- NA
names(PPFD_df) <- c("lon","lat","PPFD")

alpha_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/alpha.nc"), varnam = "alpha")
#alpha_df$myvar[alpha_df$myvar == 9999] <- NA
names(alpha_df) <- c("lon","lat","alpha")

merge1 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                list(Tg_df,PPFD_df,alpha_df,LMA_df))
summary(merge1) # we will start knn from here, it is clear that LMA has less data, and this is what we aim to interpolate based on knn

merge2 <- subset(merge1,PPFD>0) # only select available grids (in land). This will be furtherly used to determine training and testing (predicted) data.
dim(merge2)

#(2) start knn

all_data <- merge2[,c("LMA","lat","Tg","alpha","PPFD")] # this is final input will be used in knn, which removed lon here.

training_data <- subset(all_data,LMA>0) #only select available LMA data as training data

testing_data <- subset(all_data,is.na(LMA)==TRUE)  #only select NA-LMA data as testing data, which will be used in knn at the end.

dim(training_data)
dim(testing_data)

# we will use those 19020 grids to predict those 44816 grids
# 3. knn training
cv <- trainControl(
  method = "cv", 
  number = 10
)

# Create a hyperparameter grid search
hyper_grid <- expand.grid(
  k = floor(seq(1, 15, length.out = 16))
)
library(keras)
set.seed(2)
knn_fit <- train(LMA ~., data = training_data,
                 method = "knn",
                 trControl=cv,
                 preProcess = c("center", "scale"),
                 tuneGrid = hyper_grid)

knn_fit # it indicated k =9 as the best design, with R2=0.61, RMSE = 10.58

# output prediction data and add it in testing_data
set.seed(2)
test_pred <- predict(knn_fit,newdata=testing_data)
testing_data$LMA <- test_pred

#rbind, and merge back with lon.
final <- rbind(training_data,testing_data)

lon_data <- merge2[,c("lon","lat","Tg","alpha","PPFD")]

final2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lat","Tg","alpha","PPFD"),all.x=TRUE), 
                list(final,lon_data))

#form final3 dataframe as final output, and plot
LMA_knn_df <- final2[,c("lon","lat","LMA")]

#This map is LMA after knn method
plot_map3(LMA_knn_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#Finally, ready to be outputted! It merges from 63836 grids to 259200 cells, which makes it as a perfect standard for nimpl input
LMA_knn_df2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                     list(merge1[,c("lon","lat")],LMA_knn_df))

df_LMA <- LMA_knn_df2[order(LMA_knn_df2[,2],LMA_knn_df2[,1]),]

#prepare lon and lat
ncin <- nc_open("~/data/watch_wfdei/WFDEI-elevation.nc")
lon <- ncvar_get(ncin,"lon")
lat<-ncvar_get(ncin,"lat")

#output nc file - In Euler its path is same: "~/data/nimpl_sofun_inputs/map/Final_ncfile"
LMA_nc <- list(df_to_grid(df_LMA,varnam = "LMA", lonnam = "lon", latnam = "lat"))
names(LMA_nc) <- "LMA"
varams = "LMA"
test <- list(lon,lat,LMA_nc,varams)
names(test) <- c("lon","lat","vars","varams")
write_nc2(test,varnams = "LMA",long_name = "Leaf mass per area",units = "g m-2",
          path = "~/data/nimpl_sofun_inputs/map/Final_ncfile/LMA.nc")

knn_fit
summary(df_LMA)
df_LMA3 <- df_LMA
```  

## Forth time LMA output
```{r}
library(raster)
library(ncdf4)
library(dplyr)
library(maps)
library(rgdal)
#1. Input 0.5 resolution df, and convert to raster before resampling (e.g. elevation.nc)
elev_nc <- read_nc_onefile("~/data/watch_wfdei/WFDEI-elevation.nc")
elev <- as.data.frame(nc_to_df(elev_nc, varnam = "elevation"))
summary(elev)
names(elev) <- c("lon","lat","z")
coordinates(elev) <- ~lon+lat 
gridded(elev) <- TRUE
raster_z <- raster(elev, "z") 

bounding_box <- extent(-180, 180, -90, 90)
raster_z_crop <- crop(raster_z, bounding_box)
raster_z_crop

#2. Input 3km LMA raster that needs resampled
#Original data source: https://isp.uv.es/code/try.html
raster_SLA <- raster("~/data/TRY_maps/data_orig/SLA_3km_v1.tif")
raster_SLA_crop <- crop(raster_SLA, bounding_box)
raster_SLA_crop

#raster of SLA (0.02694946* 0.02694946) will be resampled to 0.5*0.5 resolution, based on provided elevation raster 
res(raster_z_crop)
res(raster_SLA_crop)

resampled_SLA <- raster::resample(raster_SLA_crop, raster_z_crop, method="ngb")
df_SLA <- stack(resampled_SLA)
df_SLA <- as.data.frame(df_SLA,xy = TRUE)
names(df_SLA) <- c("lon","lat","SLA")
summary(df_SLA)

df_SLA2 <- subset(df_SLA,(SLA > 0)) # remove some amazingly wrong number (negative!)
df_SLA2$LMA <- 1000/df_SLA2$SLA #mm2/mg -> g/m2
LMA_df <- df_SLA2[,c("lon","lat","LMA")]  


library(raster)
library(ncdf4)
library(dplyr)      # for data wrangling
library(ggplot2)    # for awesome graphics
library(rsample)    # for creating validation splits
library(recipes)    # for feature engineering
# Modeling packages
library(caret)       # for fitting KNN models
library(h2o)       # for resampling and model training
library(AmesHousing)
library(modeldata)
library(rsample)
library(dslabs)
library(purrr)
library(randomForest)

# recap
summary(LMA_df)
dim(LMA_df)

#Map after resamping
plot_map3(LMA_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#We start our work from here - using knn method to fill our grids

#(1) first, input Tg, PPFD, alpha directly from final_nc/ (the data directly used in nimpl simulation)
# NA value was converted to 9999 in previous step (to prevent FPE in nimpl), therefore, converting it back
Tg_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/Tg.nc"), varnam = "Tg")
#Tg_df$myvar[Tg_df$myvar == 9999] <- NA
names(Tg_df) <- c("lon","lat","Tg")

PPFD_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/PPFD.nc"), varnam = "PPFD")
#PPFD_df$myvar[PPFD_df$myvar == 9999] <- NA
names(PPFD_df) <- c("lon","lat","PPFD")

alpha_df <- nc_to_df(read_nc_onefile("~/data/nimpl_sofun_inputs/map/Final_ncfile/alpha.nc"), varnam = "alpha")
#alpha_df$myvar[alpha_df$myvar == 9999] <- NA
names(alpha_df) <- c("lon","lat","alpha")

merge1 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                list(Tg_df,PPFD_df,alpha_df,LMA_df))
summary(merge1) # we will start knn from here, it is clear that LMA has less data, and this is what we aim to interpolate based on knn

merge2 <- subset(merge1,PPFD>0) # only select available grids (in land). This will be furtherly used to determine training and testing (predicted) data.
dim(merge2)

#(2) start knn

all_data <- merge2[,c("LMA","lat","Tg","alpha","PPFD")] # this is final input will be used in knn, which removed lon here.

training_data <- subset(all_data,LMA>0) #only select available LMA data as training data

testing_data <- subset(all_data,is.na(LMA)==TRUE)  #only select NA-LMA data as testing data, which will be used in knn at the end.

dim(training_data)
dim(testing_data)

# we will use those 19020 grids to predict those 44816 grids
# 3. knn training
cv <- trainControl(
  method = "cv", 
  number = 10
)

# Create a hyperparameter grid search
hyper_grid <- expand.grid(
  k = floor(seq(1, 15, length.out = 16))
)
library(keras)
set.seed(2)
knn_fit <- train(LMA ~., data = training_data,
                 method = "knn",
                 trControl=cv,
                 preProcess = c("center", "scale"),
                 tuneGrid = hyper_grid)

knn_fit # it indicated k =9 as the best design, with R2=0.61, RMSE = 10.58

# output prediction data and add it in testing_data
set.seed(2)
test_pred <- predict(knn_fit,newdata=testing_data)
testing_data$LMA <- test_pred

#rbind, and merge back with lon.
final <- rbind(training_data,testing_data)

lon_data <- merge2[,c("lon","lat","Tg","alpha","PPFD")]

final2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lat","Tg","alpha","PPFD"),all.x=TRUE), 
                list(final,lon_data))

#form final3 dataframe as final output, and plot
LMA_knn_df <- final2[,c("lon","lat","LMA")]

#This map is LMA after knn method
plot_map3(LMA_knn_df, 
          varnam = "LMA",plot_title = " LMA (g m-2)",
          latmin = -65, latmax = 85)

#Finally, ready to be outputted! It merges from 63836 grids to 259200 cells, which makes it as a perfect standard for nimpl input
LMA_knn_df2 <-Reduce(function(x,y) merge(x = x, y = y, by = c("lon","lat"),all.x=TRUE), 
                     list(merge1[,c("lon","lat")],LMA_knn_df))

df_LMA <- LMA_knn_df2[order(LMA_knn_df2[,2],LMA_knn_df2[,1]),]

#prepare lon and lat
ncin <- nc_open("~/data/watch_wfdei/WFDEI-elevation.nc")
lon <- ncvar_get(ncin,"lon")
lat<-ncvar_get(ncin,"lat")

#output nc file - In Euler its path is same: "~/data/nimpl_sofun_inputs/map/Final_ncfile"
LMA_nc <- list(df_to_grid(df_LMA,varnam = "LMA", lonnam = "lon", latnam = "lat"))
names(LMA_nc) <- "LMA"
varams = "LMA"
test <- list(lon,lat,LMA_nc,varams)
names(test) <- c("lon","lat","vars","varams")
write_nc2(test,varnams = "LMA",long_name = "Leaf mass per area",units = "g m-2",
          path = "~/data/nimpl_sofun_inputs/map/Final_ncfile/LMA.nc")

knn_fit
summary(df_LMA)
df_LMA4 <- df_LMA
```  

## Check four times simulation
```{r}
summary(df_LMA2 - df_LMA1)
summary(df_LMA3 - df_LMA2)
summary(df_LMA4 - df_LMA3)
```  